{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import metrics\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = {\n",
    "    \"s1\": [],\n",
    "    \"s2\": [],\n",
    "    \"dataset\": [],\n",
    "    \"value\": [],\n",
    "    \"type\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
       "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10, the ship's owners had published an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
       "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Revenue in the first quarter of the year dropp...</td>\n",
       "      <td>With the scandal hanging over Stewart's compan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>The DVD-CCA then appealed to the state Supreme...</td>\n",
       "      <td>The DVD CCA appealed that decision to the U.S....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                 s1  \\\n",
       "0           0  Amrozi accused his brother, whom he called \"th...   \n",
       "2           2  They had published an advertisement on the Int...   \n",
       "4           4  The stock rose $2.11, or about 11 percent, to ...   \n",
       "5           5  Revenue in the first quarter of the year dropp...   \n",
       "7           7  The DVD-CCA then appealed to the state Supreme...   \n",
       "\n",
       "                                                  s2  label  \n",
       "0  Referring to him as only \"the witness\", Amrozi...      1  \n",
       "2  On June 10, the ship's owners had published an...      1  \n",
       "4  PG&E Corp. shares jumped $1.63 or 8 percent to...      1  \n",
       "5  With the scandal hanging over Stewart's compan...      1  \n",
       "7  The DVD CCA appealed that decision to the U.S....      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./mrpc/mrpc_train.csv\")\n",
    "df_train = df_train[df_train[\"label\"]==1]\n",
    "df_test = pd.read_csv(\"./mrpc/mrpc_test.csv\")\n",
    "df_test = df_test[df_test[\"label\"]==1]\n",
    "df = pd.concat([df_train, df_test])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3900 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "  0%|          | 11/3900 [00:00<00:38, 101.06it/s]/opt/conda/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "100%|██████████| 3900/3900 [00:34<00:00, 113.27it/s]\n"
     ]
    }
   ],
   "source": [
    "pos_dev_list = []\n",
    "lex_dev_list = []\n",
    "edit_dist_list = []\n",
    "rougel_list = []\n",
    "sbleu_list = []\n",
    "s1_list = []\n",
    "s2_list = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    s1 = metrics.preprocess_text(row[\"s1\"])\n",
    "    s2 = metrics.preprocess_text(row[\"s2\"])\n",
    "    assert len(s1) > 4 and len(s2) > 4\n",
    "    s1_list.append(s1)\n",
    "    s2_list.append(s2)\n",
    "    s1, s2 = s1.lower(), s2.lower()\n",
    "    edit_dist_list.append(metrics.edit_distance(s1, s2))\n",
    "    rougel_list.append(metrics.rouge_l(s1, s2))\n",
    "    sbleu_list.append(metrics.self_bleu(s1, s2))\n",
    "    s1 = nlp(s1)\n",
    "    s2 = nlp(s2)\n",
    "    pos_dev_list.append(metrics.wpd(s1, s2))\n",
    "    lex_dev_list.append(metrics.ld(s1, s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data[\"s1\"] += s1_list\n",
    "output_data[\"s2\"] += s2_list\n",
    "\n",
    "output_data[\"value\"] += pos_dev_list\n",
    "output_data[\"dataset\"] += [\"mrpc\"]*len(pos_dev_list)\n",
    "output_data[\"type\"] += [\"position deviation\"]*len(pos_dev_list)\n",
    "\n",
    "output_data[\"s1\"] += s1_list\n",
    "output_data[\"s2\"] += s2_list\n",
    "\n",
    "output_data[\"value\"] += lex_dev_list\n",
    "output_data[\"dataset\"] += [\"mrpc\"]*len(lex_dev_list)\n",
    "output_data[\"type\"] += [\"lexical deviation\"]*len(lex_dev_list)\n",
    "\n",
    "output_data[\"s1\"] += s1_list\n",
    "output_data[\"s2\"] += s2_list\n",
    "\n",
    "output_data[\"value\"] += edit_dist_list\n",
    "output_data[\"dataset\"] += [\"mrpc\"]*len(edit_dist_list)\n",
    "output_data[\"type\"] += [\"edit distance\"]*len(edit_dist_list)\n",
    "\n",
    "output_data[\"s1\"] += s1_list\n",
    "output_data[\"s2\"] += s2_list\n",
    "\n",
    "output_data[\"value\"] += rougel_list\n",
    "output_data[\"dataset\"] += [\"mrpc\"]*len(rougel_list)\n",
    "output_data[\"type\"] += [\"rouge-l\"]*len(rougel_list)\n",
    "\n",
    "output_data[\"s1\"] += s1_list\n",
    "output_data[\"s2\"] += s2_list\n",
    "\n",
    "output_data[\"value\"] += sbleu_list\n",
    "output_data[\"dataset\"] += [\"mrpc\"]*len(sbleu_list)\n",
    "output_data[\"type\"] += [\"self-bleu\"]*len(sbleu_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21829, 4)\n",
      "(3539, 4)\n",
      "(3536, 4)\n",
      "(28904, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The NBA season of 1975 -- 76 was the 30th seas...</td>\n",
       "      <td>The 1975 -- 76 season of the National Basketba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>When comparable rates of flow can be maintaine...</td>\n",
       "      <td>The results are high when comparable flow rate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>It is the seat of Zerendi District in Akmola R...</td>\n",
       "      <td>It is the seat of the district of Zerendi in A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>William Henry Henry Harman was born on 17 Febr...</td>\n",
       "      <td>William Henry Harman was born in Waynesboro , ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>With a discrete amount of probabilities Formul...</td>\n",
       "      <td>Given a discrete set of probabilities formula ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          sentence1  \\\n",
       "1   2  The NBA season of 1975 -- 76 was the 30th seas...   \n",
       "3   4  When comparable rates of flow can be maintaine...   \n",
       "4   5  It is the seat of Zerendi District in Akmola R...   \n",
       "5   6  William Henry Henry Harman was born on 17 Febr...   \n",
       "7   8  With a discrete amount of probabilities Formul...   \n",
       "\n",
       "                                           sentence2  label  \n",
       "1  The 1975 -- 76 season of the National Basketba...      1  \n",
       "3  The results are high when comparable flow rate...      1  \n",
       "4  It is the seat of the district of Zerendi in A...      1  \n",
       "5  William Henry Harman was born in Waynesboro , ...      1  \n",
       "7  Given a discrete set of probabilities formula ...      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./paws/train.tsv\", sep=\"\\t\")\n",
    "df_train = df_train[df_train[\"label\"]==1]\n",
    "print(df_train.shape)\n",
    "df_dev = pd.read_csv(\"./paws/dev.tsv\", sep=\"\\t\")\n",
    "df_dev = df_dev[df_dev[\"label\"]==1]\n",
    "print(df_dev.shape)\n",
    "df_test = pd.read_csv(\"./paws/test.tsv\", sep=\"\\t\")\n",
    "df_test = df_test[df_test[\"label\"]==1]\n",
    "print(df_test.shape)\n",
    "df = pd.concat([df_train, df_dev, df_test])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28904 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "  0%|          | 63/28904 [00:00<04:10, 115.24it/s]/opt/conda/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "  4%|▎         | 1066/28904 [00:09<03:56, 117.67it/s]/opt/conda/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "100%|██████████| 28904/28904 [04:01<00:00, 119.86it/s]\n"
     ]
    }
   ],
   "source": [
    "pos_dev_list = []\n",
    "lex_dev_list = []\n",
    "edit_dist_list = []\n",
    "rougel_list = []\n",
    "sbleu_list = []\n",
    "s1_list = []\n",
    "s2_list = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    s1 = metrics.preprocess_text(row[\"sentence1\"])\n",
    "    s2 = metrics.preprocess_text(row[\"sentence2\"])\n",
    "    s1_list.append(s1)\n",
    "    s2_list.append(s2)\n",
    "    s1, s2 = s1.lower(), s2.lower()\n",
    "    edit_dist_list.append(metrics.edit_distance(s1, s2))\n",
    "    rougel_list.append(metrics.rouge_l(s1, s2))\n",
    "    sbleu_list.append(metrics.self_bleu(s1, s2))\n",
    "    s1 = nlp(s1)\n",
    "    s2 = nlp(s2)\n",
    "    pos_dev_list.append(metrics.wpd(s1, s2))\n",
    "    lex_dev_list.append(metrics.ld(s1, s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data[\"s1\"] += s1_list\n",
    "output_data[\"s2\"] += s2_list\n",
    "\n",
    "output_data[\"value\"] += pos_dev_list\n",
    "output_data[\"dataset\"] += [\"paws\"]*len(pos_dev_list)\n",
    "output_data[\"type\"] += [\"position deviation\"]*len(pos_dev_list)\n",
    "\n",
    "output_data[\"s1\"] += s1_list\n",
    "output_data[\"s2\"] += s2_list\n",
    "\n",
    "output_data[\"value\"] += lex_dev_list\n",
    "output_data[\"dataset\"] += [\"paws\"]*len(lex_dev_list)\n",
    "output_data[\"type\"] += [\"lexical deviation\"]*len(lex_dev_list)\n",
    "\n",
    "output_data[\"s1\"] += s1_list\n",
    "output_data[\"s2\"] += s2_list\n",
    "\n",
    "output_data[\"value\"] += edit_dist_list\n",
    "output_data[\"dataset\"] += [\"paws\"]*len(edit_dist_list)\n",
    "output_data[\"type\"] += [\"edit distance\"]*len(edit_dist_list)\n",
    "\n",
    "output_data[\"s1\"] += s1_list\n",
    "output_data[\"s2\"] += s2_list\n",
    "\n",
    "output_data[\"value\"] += rougel_list\n",
    "output_data[\"dataset\"] += [\"paws\"]*len(rougel_list)\n",
    "output_data[\"type\"] += [\"rouge-l\"]*len(rougel_list)\n",
    "\n",
    "output_data[\"s1\"] += s1_list\n",
    "output_data[\"s2\"] += s2_list\n",
    "\n",
    "output_data[\"value\"] += sbleu_list\n",
    "output_data[\"dataset\"] += [\"paws\"]*len(sbleu_list)\n",
    "output_data[\"type\"] += [\"self-bleu\"]*len(sbleu_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>dataset</th>\n",
       "      <th>value</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
       "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>0.199770</td>\n",
       "      <td>position deviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10, the ship's owners had published an...</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>0.240221</td>\n",
       "      <td>position deviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
       "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>position deviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Revenue in the first quarter of the year dropp...</td>\n",
       "      <td>With the scandal hanging over Stewart's compan...</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>0.137821</td>\n",
       "      <td>position deviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The DVD-CCA then appealed to the state Supreme...</td>\n",
       "      <td>The DVD CCA appealed that decision to the U.S....</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>0.067235</td>\n",
       "      <td>position deviation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  s1  \\\n",
       "0  Amrozi accused his brother, whom he called \"th...   \n",
       "1  They had published an advertisement on the Int...   \n",
       "2  The stock rose $2.11, or about 11 percent, to ...   \n",
       "3  Revenue in the first quarter of the year dropp...   \n",
       "4  The DVD-CCA then appealed to the state Supreme...   \n",
       "\n",
       "                                                  s2 dataset     value  \\\n",
       "0  Referring to him as only \"the witness\", Amrozi...    mrpc  0.199770   \n",
       "1  On June 10, the ship's owners had published an...    mrpc  0.240221   \n",
       "2  PG&E Corp. shares jumped $1.63 or 8 percent to...    mrpc  0.196429   \n",
       "3  With the scandal hanging over Stewart's compan...    mrpc  0.137821   \n",
       "4  The DVD CCA appealed that decision to the U.S....    mrpc  0.067235   \n",
       "\n",
       "                 type  \n",
       "0  position deviation  \n",
       "1  position deviation  \n",
       "2  position deviation  \n",
       "3  position deviation  \n",
       "4  position deviation  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out = pd.DataFrame.from_dict(output_data)\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>dataset</th>\n",
       "      <th>value</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>164015</th>\n",
       "      <td>Twice Sparrow sold the island twice to Thomas ...</td>\n",
       "      <td>Sparrow twice sold the island to Thomas Polloc...</td>\n",
       "      <td>paws</td>\n",
       "      <td>0.672318</td>\n",
       "      <td>self-bleu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164016</th>\n",
       "      <td>The name in Tupi means \" insensitive stone \", ...</td>\n",
       "      <td>The name in Tupi means \" hard stone \", \" insen...</td>\n",
       "      <td>paws</td>\n",
       "      <td>0.596990</td>\n",
       "      <td>self-bleu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164017</th>\n",
       "      <td>The company has branches in Tokyo, based in th...</td>\n",
       "      <td>The company has branches in Tokyo based in Sai...</td>\n",
       "      <td>paws</td>\n",
       "      <td>0.455616</td>\n",
       "      <td>self-bleu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164018</th>\n",
       "      <td>The modern coat of arms of Bavaria was designe...</td>\n",
       "      <td>The modern coat of arms of Bavaria was designe...</td>\n",
       "      <td>paws</td>\n",
       "      <td>0.573057</td>\n",
       "      <td>self-bleu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164019</th>\n",
       "      <td>It is located near Point Pleasant Borough, a m...</td>\n",
       "      <td>It is near Point Pleasant borough, a municipal...</td>\n",
       "      <td>paws</td>\n",
       "      <td>0.487649</td>\n",
       "      <td>self-bleu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       s1  \\\n",
       "164015  Twice Sparrow sold the island twice to Thomas ...   \n",
       "164016  The name in Tupi means \" insensitive stone \", ...   \n",
       "164017  The company has branches in Tokyo, based in th...   \n",
       "164018  The modern coat of arms of Bavaria was designe...   \n",
       "164019  It is located near Point Pleasant Borough, a m...   \n",
       "\n",
       "                                                       s2 dataset     value  \\\n",
       "164015  Sparrow twice sold the island to Thomas Polloc...    paws  0.672318   \n",
       "164016  The name in Tupi means \" hard stone \", \" insen...    paws  0.596990   \n",
       "164017  The company has branches in Tokyo based in Sai...    paws  0.455616   \n",
       "164018  The modern coat of arms of Bavaria was designe...    paws  0.573057   \n",
       "164019  It is near Point Pleasant borough, a municipal...    paws  0.487649   \n",
       "\n",
       "             type  \n",
       "164015  self-bleu  \n",
       "164016  self-bleu  \n",
       "164017  self-bleu  \n",
       "164018  self-bleu  \n",
       "164019  self-bleu  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv(\"./dataset_stats.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
